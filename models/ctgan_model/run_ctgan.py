"""
CTGAN runner (MIMIC-style defaults, easy to edit)
Produces:
- A real static patient table (Parquet) used as baseline covariates
- A synthetic static patient table (Parquet) generated by CTGAN

This version outputs CTGAN synthetic rows using the same patient ids as the
train cohort. That makes the synthetic static table mergeable onto the
longitudinal data by id.

Outputs (by default in results/ctgan_results/):
- real_static.parquet
- ctgan_static.parquet
- ctgan_config.json (the metadata)
"""

from __future__ import annotations

import json
import os
import pickle
import numpy as np
import pandas as pd

from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional, Tuple

from ctgan import CTGAN


# DEFAULTS ------------------------------ #

DEFAULT_PATIENT_ID_COL = "subject_id"
DEFAULT_TIME_COL = "time"


# UTILS --------------------------------------- #

def ensure_dir(p: Path) -> None:
    p.mkdir(parents=True, exist_ok=True)


def save_json(path: Path, obj: dict) -> None:
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, indent=2)


def load_parquet(path: Path) -> pd.DataFrame:
    return pd.read_parquet(path)


def infer_discrete_columns(df: pd.DataFrame, patient_id_col: str) -> List[str]:
    discrete = []
    for c in df.columns:
        if c == patient_id_col:
            continue
        # treats object/category/bool as discrete
        if pd.api.types.is_object_dtype(df[c]) or pd.api.types.is_categorical_dtype(df[c]) or pd.api.types.is_bool_dtype(df[c]):
            discrete.append(c)
    return discrete


def _read_json(path: str) -> dict:
    with open(path, "r", encoding="utf-8") as f:
        obj = json.load(f)
    if not isinstance(obj, dict):
        raise ValueError(f"Expected JSON object in {path}")
    return obj


def _load_train_ids(split_ids_json: str) -> List[str]:
    obj = _read_json(split_ids_json)
    for k in ["train_ids", "train", "train_patient_ids", "train_subject_ids"]:
        v = obj.get(k)
        if isinstance(v, list):
            return [str(x) for x in v]
    raise ValueError(
        f"Could not find train ids list in {split_ids_json}. Expected key like 'train_ids'."
    )


def split_patients(
    patient_table: pd.DataFrame,
    patient_id_col: str,
    test_fraction: float,
    seed: int,
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """Patient-level split: returns train_patients, test_patients (static tables)."""
    ids = patient_table[patient_id_col].astype(str).unique().tolist()
    rng = np.random.default_rng(seed)
    rng.shuffle(ids)

    n = len(ids)
    n_test = int(round(n * test_fraction))
    test_ids = set(ids[:n_test])
    train_mask = ~patient_table[patient_id_col].astype(str).isin(test_ids)
    test_mask = ~train_mask
    return patient_table.loc[train_mask].copy(), patient_table.loc[test_mask].copy()


def long_to_static(
    long_df: pd.DataFrame,
    patient_id_col: str,
    time_col: Optional[str],
    aggregation: str = "last",
) -> pd.DataFrame:
    """
    Convers long-format time-series to one-row-per-patient static table.
    Aggregation options:
      - last: last observed value by time per column
      - mean: numeric columns mean; non-numeric use last
    """
    if time_col is None:
        # already static
        return long_df.copy()

    if time_col not in long_df.columns:
        raise ValueError(f"time_col='{time_col}' not found in long dataframe")

    df = long_df.copy()
    df[patient_id_col] = df[patient_id_col].astype(str)

    # sorts by time within patient
    df = df.sort_values([patient_id_col, time_col])

    if aggregation == "last":
        # takes last row per patient, but keep all columns
        static = df.groupby(patient_id_col, as_index=False).tail(1)
        # ensures one row per patient
        static = static.drop(columns=[time_col], errors="ignore")
        static = static.groupby(patient_id_col, as_index=False).first()
        return static

    if aggregation == "mean":
        # numeric mean, others last
        numeric_cols = [c for c in df.columns if c not in {patient_id_col, time_col} and pd.api.types.is_numeric_dtype(df[c])]
        other_cols = [c for c in df.columns if c not in {patient_id_col, time_col} and c not in numeric_cols]

        means = df.groupby(patient_id_col, as_index=False)[numeric_cols].mean() if numeric_cols else df[[patient_id_col]].drop_duplicates()

        # FIX: for non-numeric columns use MODE if possible, else fallback to last
        if other_cols:
            def mode_or_last(s: pd.Series):
                m = s.mode(dropna=True)
                if len(m):
                    return m.iloc[0]
                nn = s.dropna()
                return nn.iloc[-1] if len(nn) else s.iloc[-1]

            other = df.groupby(patient_id_col, as_index=False)[other_cols].agg(mode_or_last)
        else:
            other = df[[patient_id_col]].drop_duplicates()

        static = means.merge(other, on=patient_id_col, how="left")
        return static

    raise ValueError(f"Unknown aggregation='{aggregation}'. Use last or mean")


def handle_missing_values(
    feature_df: pd.DataFrame,
    discrete_cols: List[str],
    mode: str,
    flag_suffix: str = "__is_missing",
) -> pd.DataFrame:
    """
    Missing values management options for CTGAN:
      - drop: drop rows with any NA (bad I think)
      - simple: fills numeric with median, discrete with mode
      - indicators: adds missingness flags + then fills like simple option
    """
    df = feature_df.copy()
    # dropping columns that are entirely missing
    all_null = [c for c in df.columns if df[c].isna().all()]
    if all_null:
        df = df.drop(columns=all_null)
        # keep discrete_cols consistent
        for c in list(discrete_cols):
            if c in all_null:
                discrete_cols.remove(c)


    if mode == "drop":
        return df.dropna(axis=0).reset_index(drop=True)

    # indicators
    if mode == "indicators":
        for c in df.columns:
            if df[c].isna().any():
                df[c + flag_suffix] = df[c].isna().astype(int)
                # missing flag is discrete
                if c + flag_suffix not in discrete_cols:
                    discrete_cols.append(c + flag_suffix)

    # simple fill
    for c in df.columns:
        if not df[c].isna().any():
            continue
        if c in discrete_cols or pd.api.types.is_object_dtype(df[c]) or pd.api.types.is_bool_dtype(df[c]):
            # mode fill
            mode_val = df[c].mode(dropna=True)
            fill_val = mode_val.iloc[0] if len(mode_val) else "MISSING"
            df[c] = df[c].fillna(fill_val)
        else:
            # numeric median fill
            med = df[c].median()
            df[c] = df[c].fillna(med)

    return df.reset_index(drop=True)


# CONFIGURATION ------------------------------ #

@dataclass
class CTGANConfig:
    # Paths
    input_table_path: str = "data/processed/physionet2012_long.parquet"
    output_folder: str = "results/ctgan/physionet2012"
    output_file_name: str = "ctgan_static.parquet"  # will also write real_static.parquet

    # Column names TO-DO: adapt to dataset later
    patient_id_col: str = "patient_id"
    time_col: Optional[str] = "t"  # if the input is already static set to none

    # Long to static behavior:
    static_aggregation: str = "mean"  # last or mean

    # CTGAN split
    # train only is used for fitting
    test_fraction: float = 0.0  # keep 0 if we want a training-cohort static table

    # Missing values handling
    missing_mode: str = "indicators"  # "drop" o "simple" or "indicators"
    missing_flag_suffix: str = "__is_missing"

    # Discrete columns: if None then inferred automatically
    discrete_columns: Optional[List[str]] = None

    # Reuse an authoritative upstream patient split
    train_split_ids_json: Optional[str] = "results/itransformer/physionet2012_itransformer/split_ids.json"  # took it from iTransformer outputs

    # CTGAN hyperparameters
    seed: int = 42
    epochs: int = 300
    batch_size: int = 500
    verbose: bool = True



# MAIN ------------------------------------------- #

def run(cfg: CTGANConfig) -> None:
    input_path = Path(cfg.input_table_path)
    output_dir = Path(cfg.output_folder)
    ensure_dir(output_dir)

    # 1. Load
    df = load_parquet(input_path)

    if cfg.patient_id_col not in df.columns:
        raise ValueError(f"patient_id_col='{cfg.patient_id_col}' not found in input table")

    # 2. Long to static table
    patient_table = long_to_static(
        long_df=df,
        patient_id_col=cfg.patient_id_col,
        time_col=cfg.time_col,
        aggregation=cfg.static_aggregation,
    )

    # enforces id as string
    patient_table[cfg.patient_id_col] = patient_table[cfg.patient_id_col].astype(str)

    # 3. Decides discrete columns
    if cfg.discrete_columns is None:
        discrete_cols = infer_discrete_columns(patient_table, cfg.patient_id_col)
        # FIX: force coded categorical columns to be discrete even if numeric dtype
        for must in ["Gender", "ICUType"]:
            if must in patient_table.columns and must not in discrete_cols:
                discrete_cols.append(must)
    else:
        discrete_cols = [c for c in cfg.discrete_columns if c in patient_table.columns]

    # 4. Patient-level split
    # CTGAN fits on train_patients only
    if cfg.train_split_ids_json:
        train_ids = set(_load_train_ids(cfg.train_split_ids_json))
        train_patients = patient_table[patient_table[cfg.patient_id_col].astype(str).isin(train_ids)].copy()
        if train_patients.empty:
            raise ValueError(
                f"No patients matched train_ids from {cfg.train_split_ids_json}. "
                f"Check id format and patient_id_col."
            )
    else:
        train_patients, _ = split_patients(
            patient_table=patient_table,
            patient_id_col=cfg.patient_id_col,
            test_fraction=cfg.test_fraction,
            seed=cfg.seed,
        )

    # Saves the real static baseline table for this cohort
    real_static_out = output_dir / "real_static.parquet"
    train_patients.to_parquet(real_static_out, index=False)

    # 5. Prepares training matrix for CTGAN
    # features only
    X_train = train_patients.drop(columns=[cfg.patient_id_col]).reset_index(drop=True)

    # 6. Missing handling
    X_train = handle_missing_values(
        feature_df=X_train,
        discrete_cols=discrete_cols,
        mode=cfg.missing_mode,
        flag_suffix=cfg.missing_flag_suffix,
    )

    # missingness flags are discrete
    if cfg.missing_mode == "indicators":
        for c in X_train.columns:
            if c.endswith(cfg.missing_flag_suffix) and c not in discrete_cols:
                discrete_cols.append(c)

    # 7. Fits CTGAN
    np.random.seed(cfg.seed)

    ctgan = CTGAN(
        epochs=cfg.epochs,
        batch_size=cfg.batch_size,
        verbose=cfg.verbose,
    )
    ctgan.fit(X_train, discrete_columns=discrete_cols)

    # FIX: save model artifact for reproducibility (does not affect downstream)
    with open(output_dir / "ctgan_model.pkl", "wb") as f:
        pickle.dump(ctgan, f)

    # 8. Samples synthetic patients
    # same num as training cohort
    synthetic_features = ctgan.sample(len(X_train))

    # FIX: enforce integer categories after sampling (and clip to observed train range)
    for col in ["Gender", "ICUType"]:
        if col in synthetic_features.columns and col in train_patients.columns:
            synthetic_features[col] = pd.to_numeric(synthetic_features[col], errors="coerce").round()
            lo = int(pd.to_numeric(train_patients[col], errors="coerce").min())
            hi = int(pd.to_numeric(train_patients[col], errors="coerce").max())
            synthetic_features[col] = synthetic_features[col].clip(lo, hi).astype("Int64")

    # FIX: use the SAME IDs as the cohort, so outputs merge by id later
    synthetic_features.insert(
        0,
        cfg.patient_id_col,
        train_patients[cfg.patient_id_col].astype(str).tolist(),
    )

    # 9. Saves outputs
    output_path = output_dir / cfg.output_file_name
    synthetic_features.to_parquet(output_path, index=False)

    meta = {
        "input_table_path": str(input_path),
        "output_folder": str(output_dir),
        "patient_id_col": cfg.patient_id_col,
        "time_col": cfg.time_col,
        "static_aggregation": cfg.static_aggregation,
        "test_fraction": cfg.test_fraction,
        "missing_mode": cfg.missing_mode,
        "epochs": cfg.epochs,
        "batch_size": cfg.batch_size,
        "seed": cfg.seed,
        "n_train_patients": int(train_patients[cfg.patient_id_col].nunique()),
        "discrete_columns": discrete_cols,
        "train_split_ids_json": cfg.train_split_ids_json,
        "real_static_path": str(real_static_out),
        "synthetic_static_path": str(output_path),
        "ctgan_model_path": str(output_dir / "ctgan_model.pkl"),
    }
    save_json(output_dir / "ctgan_config.json", meta)

    print(f"CTGAN saved real static table: {real_static_out}")
    print(f"CTGAN saved synthetic static table: {output_path}")
    print(f"CTGAN saved metadata: {output_dir / 'ctgan_config.json'}")


if __name__ == "__main__":
    # Minimal CLI: optionally reads env vars for quick overrides
    # Not quite sure about this approach but ok for now
    cfg = CTGANConfig(
        input_table_path=os.getenv("CTGAN_INPUT", CTGANConfig.input_table_path),
        output_folder=os.getenv("CTGAN_OUTDIR", CTGANConfig.output_folder),
        output_file_name=os.getenv("CTGAN_OUTFILE", CTGANConfig.output_file_name),
        patient_id_col=os.getenv("CTGAN_IDCOL", CTGANConfig.patient_id_col),
        time_col=os.getenv("CTGAN_TIMECOL", CTGANConfig.time_col),
        train_split_ids_json=os.getenv("CTGAN_SPLIT_IDS", None),
    )
    run(cfg)
